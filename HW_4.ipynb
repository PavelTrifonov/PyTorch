{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Custom CNN на CIFAR-100"
      ],
      "metadata": {
        "id": "acnKqa-agiFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs04Wb6fgXxh",
        "outputId": "c8c9dc47-d1f3-42aa-f10b-b80dbf48cd9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 87ms/step - accuracy: 0.0590 - loss: 4.2170 - val_accuracy: 0.1764 - val_loss: 3.4426\n",
            "Epoch 2/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 84ms/step - accuracy: 0.2044 - loss: 3.2926 - val_accuracy: 0.2578 - val_loss: 3.0278\n",
            "Epoch 3/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 84ms/step - accuracy: 0.2797 - loss: 2.8944 - val_accuracy: 0.2975 - val_loss: 2.8459\n",
            "Epoch 4/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 84ms/step - accuracy: 0.3321 - loss: 2.6361 - val_accuracy: 0.3345 - val_loss: 2.6663\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 84ms/step - accuracy: 0.3741 - loss: 2.4364 - val_accuracy: 0.3494 - val_loss: 2.5781\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 84ms/step - accuracy: 0.4065 - loss: 2.2826 - val_accuracy: 0.3712 - val_loss: 2.5002\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 88ms/step - accuracy: 0.4367 - loss: 2.1428 - val_accuracy: 0.3652 - val_loss: 2.5173\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 86ms/step - accuracy: 0.4601 - loss: 2.0286 - val_accuracy: 0.3986 - val_loss: 2.4330\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 85ms/step - accuracy: 0.4778 - loss: 1.9451 - val_accuracy: 0.3970 - val_loss: 2.4264\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - accuracy: 0.5040 - loss: 1.8408 - val_accuracy: 0.3960 - val_loss: 2.4168\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 86ms/step - accuracy: 0.5288 - loss: 1.7448 - val_accuracy: 0.4026 - val_loss: 2.4551\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 84ms/step - accuracy: 0.5450 - loss: 1.6605 - val_accuracy: 0.4048 - val_loss: 2.4570\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - accuracy: 0.5631 - loss: 1.5875 - val_accuracy: 0.3917 - val_loss: 2.5062\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 84ms/step - accuracy: 0.5731 - loss: 1.5333 - val_accuracy: 0.3969 - val_loss: 2.5413\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 84ms/step - accuracy: 0.5896 - loss: 1.4652 - val_accuracy: 0.3978 - val_loss: 2.5459\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 84ms/step - accuracy: 0.6063 - loss: 1.3953 - val_accuracy: 0.3972 - val_loss: 2.6480\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.6202 - loss: 1.3454 - val_accuracy: 0.4048 - val_loss: 2.6488\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 86ms/step - accuracy: 0.6302 - loss: 1.2961 - val_accuracy: 0.3977 - val_loss: 2.7404\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 85ms/step - accuracy: 0.6473 - loss: 1.2244 - val_accuracy: 0.3895 - val_loss: 2.7626\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 85ms/step - accuracy: 0.6602 - loss: 1.1730 - val_accuracy: 0.3963 - val_loss: 2.7901\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "# Загрузка данных CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Нормализация данных\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Преобразование меток в one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 100)\n",
        "\n",
        "# Определение кастомной CNN\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(100, activation='softmax')  # 100 классов для CIFAR-100\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "history = model.fit(x_train, y_train, epochs=20,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    batch_size=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning ResNet-50 на CIFAR-100"
      ],
      "metadata": {
        "id": "Qq1HVzEUgvks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Загрузка данных CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Нормализация данных\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Преобразование меток в one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 100)\n",
        "\n",
        "# Загрузка ResNet50 с предобученными весами ImageNet\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Заморозка базовой модели\n",
        "base_model.trainable = False\n",
        "\n",
        "# Добавление кастомного классификатора\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(100, activation='softmax')  # 100 классов для CIFAR-100\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "history = model.fit(x_train, y_train, epochs=20,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    batch_size=64)\n",
        "\n",
        "# Разморозка части слоев и дообучение\n",
        "base_model.trainable = True\n",
        "\n",
        "# Компиляция модели с меньшим learning_rate для fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Продолжение обучения\n",
        "history_fine = model.fit(x_train, y_train, epochs=10,\n",
        "                         validation_data=(x_test, y_test),\n",
        "                         batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9aeP-RDgbNq",
        "outputId": "1c80b7da-3814-43ac-921c-9f9dba4c45fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 275ms/step - accuracy: 0.0134 - loss: 4.6742 - val_accuracy: 0.0227 - val_loss: 4.5344\n",
            "Epoch 2/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 279ms/step - accuracy: 0.0285 - loss: 4.5184 - val_accuracy: 0.0411 - val_loss: 4.4616\n",
            "Epoch 3/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 267ms/step - accuracy: 0.0394 - loss: 4.4428 - val_accuracy: 0.0465 - val_loss: 4.4012\n",
            "Epoch 4/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 270ms/step - accuracy: 0.0523 - loss: 4.3809 - val_accuracy: 0.0501 - val_loss: 4.3474\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 279ms/step - accuracy: 0.0610 - loss: 4.3279 - val_accuracy: 0.0618 - val_loss: 4.2992\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 270ms/step - accuracy: 0.0683 - loss: 4.2795 - val_accuracy: 0.0638 - val_loss: 4.2610\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 278ms/step - accuracy: 0.0718 - loss: 4.2424 - val_accuracy: 0.0660 - val_loss: 4.2320\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 269ms/step - accuracy: 0.0795 - loss: 4.2015 - val_accuracy: 0.0742 - val_loss: 4.2051\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 271ms/step - accuracy: 0.0814 - loss: 4.1747 - val_accuracy: 0.0816 - val_loss: 4.1671\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 268ms/step - accuracy: 0.0835 - loss: 4.1505 - val_accuracy: 0.0862 - val_loss: 4.1492\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 267ms/step - accuracy: 0.0873 - loss: 4.1194 - val_accuracy: 0.0817 - val_loss: 4.1295\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 269ms/step - accuracy: 0.0901 - loss: 4.0993 - val_accuracy: 0.0864 - val_loss: 4.1093\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 271ms/step - accuracy: 0.0911 - loss: 4.0957 - val_accuracy: 0.0902 - val_loss: 4.0943\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 270ms/step - accuracy: 0.0957 - loss: 4.0684 - val_accuracy: 0.0917 - val_loss: 4.0776\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 271ms/step - accuracy: 0.0945 - loss: 4.0570 - val_accuracy: 0.0963 - val_loss: 4.0552\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 279ms/step - accuracy: 0.0999 - loss: 4.0282 - val_accuracy: 0.1001 - val_loss: 4.0473\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 279ms/step - accuracy: 0.1035 - loss: 4.0221 - val_accuracy: 0.0992 - val_loss: 4.0414\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 270ms/step - accuracy: 0.1032 - loss: 4.0008 - val_accuracy: 0.1048 - val_loss: 4.0188\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 279ms/step - accuracy: 0.1050 - loss: 3.9968 - val_accuracy: 0.1030 - val_loss: 4.0095\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 269ms/step - accuracy: 0.1075 - loss: 3.9787 - val_accuracy: 0.1062 - val_loss: 3.9977\n",
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2947s\u001b[0m 4s/step - accuracy: 0.0266 - loss: 6.3807 - val_accuracy: 0.0200 - val_loss: 27.9201\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2953s\u001b[0m 4s/step - accuracy: 0.0870 - loss: 4.1642 - val_accuracy: 0.1341 - val_loss: 5.0555\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2874s\u001b[0m 4s/step - accuracy: 0.1560 - loss: 3.7048 - val_accuracy: 0.1943 - val_loss: 3.7453\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2893s\u001b[0m 4s/step - accuracy: 0.2260 - loss: 3.3068 - val_accuracy: 0.2464 - val_loss: 3.3029\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2935s\u001b[0m 4s/step - accuracy: 0.2867 - loss: 2.9577 - val_accuracy: 0.2875 - val_loss: 3.0249\n",
            "Epoch 6/10\n",
            "\u001b[1m724/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3:32\u001b[0m 4s/step - accuracy: 0.3500 - loss: 2.6372"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning ResNet-50 с аугментацией данных"
      ],
      "metadata": {
        "id": "ls2Amvxrg1VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Загрузка данных CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Нормализация данных\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Преобразование меток в one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 100)\n",
        "\n",
        "# Аугментация данных\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Загрузка ResNet50 с предобученными весами ImageNet\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Заморозка базовой модели\n",
        "base_model.trainable = False\n",
        "\n",
        "# Добавление кастомного классификатора\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(100, activation='softmax')  # 100 классов для CIFAR-100\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели с использованием аугментации данных\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                    epochs=20,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "# Разморозка части слоев и дообучение\n",
        "base_model.trainable = True\n",
        "\n",
        "# Компиляция модели с меньшим learning_rate для fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Продолжение обучения\n",
        "history_fine = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                         epochs=10,\n",
        "                         validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIB0cvf0g6X8",
        "outputId": "7084f6b7-35a1-4d11-b28f-c8add024f1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 430ms/step - accuracy: 0.0129 - loss: 4.6683 - val_accuracy: 0.0221 - val_loss: 4.5539\n",
            "Epoch 2/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 432ms/step - accuracy: 0.0220 - loss: 4.5566 - val_accuracy: 0.0364 - val_loss: 4.4927\n",
            "Epoch 3/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 419ms/step - accuracy: 0.0282 - loss: 4.5117 - val_accuracy: 0.0405 - val_loss: 4.4554\n",
            "Epoch 4/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 423ms/step - accuracy: 0.0337 - loss: 4.4751 - val_accuracy: 0.0489 - val_loss: 4.4076\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 417ms/step - accuracy: 0.0371 - loss: 4.4503 - val_accuracy: 0.0521 - val_loss: 4.3819\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 433ms/step - accuracy: 0.0413 - loss: 4.4180 - val_accuracy: 0.0600 - val_loss: 4.3401\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 370ms/step - accuracy: 0.0455 - loss: 4.3976 - val_accuracy: 0.0587 - val_loss: 4.3167\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 380ms/step - accuracy: 0.0491 - loss: 4.3749 - val_accuracy: 0.0681 - val_loss: 4.2843\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 417ms/step - accuracy: 0.0507 - loss: 4.3553 - val_accuracy: 0.0675 - val_loss: 4.2647\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 368ms/step - accuracy: 0.0533 - loss: 4.3314 - val_accuracy: 0.0740 - val_loss: 4.2313\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 363ms/step - accuracy: 0.0527 - loss: 4.3261 - val_accuracy: 0.0737 - val_loss: 4.2194\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 416ms/step - accuracy: 0.0543 - loss: 4.3045 - val_accuracy: 0.0793 - val_loss: 4.1960\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 425ms/step - accuracy: 0.0577 - loss: 4.2921 - val_accuracy: 0.0797 - val_loss: 4.1733\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 420ms/step - accuracy: 0.0595 - loss: 4.2807 - val_accuracy: 0.0799 - val_loss: 4.1703\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 419ms/step - accuracy: 0.0622 - loss: 4.2722 - val_accuracy: 0.0843 - val_loss: 4.1538\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 422ms/step - accuracy: 0.0640 - loss: 4.2589 - val_accuracy: 0.0840 - val_loss: 4.1467\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 420ms/step - accuracy: 0.0638 - loss: 4.2500 - val_accuracy: 0.0843 - val_loss: 4.1365\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 422ms/step - accuracy: 0.0633 - loss: 4.2432 - val_accuracy: 0.0891 - val_loss: 4.1184\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 418ms/step - accuracy: 0.0636 - loss: 4.2334 - val_accuracy: 0.0875 - val_loss: 4.1172\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 423ms/step - accuracy: 0.0667 - loss: 4.2280 - val_accuracy: 0.0869 - val_loss: 4.0951\n",
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3464s\u001b[0m 4s/step - accuracy: 0.0251 - loss: 5.8155 - val_accuracy: 0.0307 - val_loss: 8.6033\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3449s\u001b[0m 4s/step - accuracy: 0.0678 - loss: 4.3039 - val_accuracy: 0.1183 - val_loss: 3.9985\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3476s\u001b[0m 4s/step - accuracy: 0.1142 - loss: 3.9579 - val_accuracy: 0.1767 - val_loss: 3.6113\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3494s\u001b[0m 4s/step - accuracy: 0.1621 - loss: 3.6511 - val_accuracy: 0.2213 - val_loss: 3.3396\n",
            "Epoch 5/10\n",
            "\u001b[1m616/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12:05\u001b[0m 4s/step - accuracy: 0.2018 - loss: 3.4067"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom CNN: Это базовая модель CNN, специально разработанная для CIFAR-100.\n",
        "\n",
        "ResNet-50: Здесь используется предобученная модель с ImageNet, заменены финальные слои для обучения на CIFAR-100.\n",
        "\n",
        "ResNet-50 с аугментацией: Добавлена аугментация данных для улучшения генерализации модели."
      ],
      "metadata": {
        "id": "TcdgJ14-hDBP"
      }
    }
  ]
}